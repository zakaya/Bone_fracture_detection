{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oBtvPNSy7sK",
        "outputId": "02abddac-0ea4-45aa-9e1b-b9b1d928d0dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/bmadushanirodrigo/fracture-multi-region-x-ray-data/versions/2\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"bmadushanirodrigo/fracture-multi-region-x-ray-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "8HOy2ikw1WDz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_nh9cQk2eXF",
        "outputId": "f054f4bb-a3d4-4f60-eee9-fb5d5262fea3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README.dataset.txt', 'Bone_Fracture_Binary_Classification']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(os.path.join(path, \"Bone_Fracture_Binary_Classification\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iNKx--62gpJ",
        "outputId": "83dd5924-dedb-4ea2-b52a-41559e4e2883"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bone_Fracture_Binary_Classification']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(os.path.join(path, \"Bone_Fracture_Binary_Classification\",\"Bone_Fracture_Binary_Classification\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joqNM3if2ptu",
        "outputId": "f1160735-2c57-41e0-e859-b7f43784b349"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test', 'val', 'train']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir=os.path.join(path, \"Bone_Fracture_Binary_Classification\",\"Bone_Fracture_Binary_Classification\",\"train\")"
      ],
      "metadata": {
        "id": "ZCjsgw5820Xf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dir=os.path.join(path, \"Bone_Fracture_Binary_Classification\",\"Bone_Fracture_Binary_Classification\",\"val\")"
      ],
      "metadata": {
        "id": "EuPUBDzf27xi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir=os.path.join(path, \"Bone_Fracture_Binary_Classification\",\"Bone_Fracture_Binary_Classification\",\"test\")"
      ],
      "metadata": {
        "id": "VSASGc5x3ASm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def find_corrupted_images(directory):\n",
        "    corrupted_files = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                img = Image.open(file_path)\n",
        "                img.verify()  # Check if the image is corrupted\n",
        "            except (IOError, SyntaxError) as e:\n",
        "                corrupted_files.append(file_path)\n",
        "                print(f\"Corrupted file: {file_path}, Error: {e}\") # Print the error for debugging\n",
        "    return corrupted_files\n",
        "\n",
        "# Assuming 'train_dir', 'valid_dir', and 'test_dir' are already defined\n",
        "train_corrupted = find_corrupted_images(train_dir)\n",
        "valid_corrupted = find_corrupted_images(valid_dir)\n",
        "test_corrupted = find_corrupted_images(test_dir)\n",
        "\n",
        "# Remove corrupted files (be careful with this!)\n",
        "# Consider backing up the files before deleting them.\n",
        "for file_path in train_corrupted + valid_corrupted + test_corrupted:\n",
        "    # os.remove(file_path)  # Uncomment to remove corrupted files\n",
        "    print(f\"Removed or replaced corrupted file: {file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu_TW6jyJ9kl",
        "outputId": "38769411-fe1d-4430-f25f-f695395e63d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def remove_corrupted_images(directory):\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                img = Image.open(file_path)\n",
        "                img.verify()  # Verify the file integrity\n",
        "            except (IOError, SyntaxError):\n",
        "                print(f\"Removing corrupted image: {file_path}\")\n",
        "                os.remove(file_path)  # Remove the corrupted file\n",
        "\n",
        "# Clean train, validation, and test directories\n",
        "remove_corrupted_images(train_dir)\n",
        "remove_corrupted_images(valid_dir)\n",
        "remove_corrupted_images(test_dir)\n"
      ],
      "metadata": {
        "id": "1IL0QKa33DYp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define image size and batch size\n",
        "IMG_SIZE = (299, 299)  # ResNet requires 224x224 images\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Load data\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\"  # Binary classification\n",
        ")\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\"  # Binary classification\n",
        ")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",  # Binary classification\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCP7UIcIO4_8",
        "outputId": "364ff275-b005-4ff6-c3e9-f657fc528ddc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9246 images belonging to 2 classes.\n",
            "Found 829 images belonging to 2 classes.\n",
            "Found 506 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow --upgrade # Upgrade to latest version or install if you haven't installed yet\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFile # Import ImageFile instead of UnImagePlugin\n",
        "\n",
        "# Define image size and batch size\n",
        "IMG_SIZE = (299, 299)  # ResNet requires 224x224 images\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "# ... (rest of your code)\n",
        "\n",
        "# Load data, incorporating error handling for corrupted images\n",
        "def load_data_with_error_handling(directory, datagen, target_size, batch_size, class_mode, shuffle=True):\n",
        "    \"\"\"\n",
        "    Loads data from a directory, handling corrupted image files gracefully.\n",
        "    \"\"\"\n",
        "    ImageFile.LOAD_TRUNCATED_IMAGES = True # Set ImageFile.LOAD_TRUNCATED_IMAGES to True\n",
        "    i = 0\n",
        "    while True:\n",
        "        try:\n",
        "            data_generator = datagen.flow_from_directory(\n",
        "                directory,\n",
        "                target_size=target_size,\n",
        "                batch_size=batch_size,\n",
        "                class_mode=class_mode,\n",
        "                shuffle=shuffle\n",
        "            )\n",
        "            # If this point is reached, data loading was successful\n",
        "            break  # Exit the loop\n",
        "        except Exception as e:  # Handle generic exceptions during data loading\n",
        "            i += 1\n",
        "            print(f\"Error encountered: {e}. Attempt {i}. Retrying...\")\n",
        "            if i >= 5:  # Maximum retry attempts\n",
        "                print(\"Maximum retry attempts reached. Aborting data loading.\")\n",
        "                raise  # Re-raise the exception if max attempts are reached\n",
        "            # Handle the corrupted file or error appropriately\n",
        "            # E.g., log the error, skip the file, or replace it with a placeholder\n",
        "    return data_generator\n",
        "train_data = load_data_with_error_handling(train_dir, train_datagen, IMG_SIZE, BATCH_SIZE, \"binary\")\n",
        "valid_data = load_data_with_error_handling(valid_dir, valid_datagen, IMG_SIZE, BATCH_SIZE, \"binary\")\n",
        "test_data = load_data_with_error_handling(test_dir, test_datagen, IMG_SIZE, BATCH_SIZE, \"binary\", shuffle=False)\n",
        "# ... (rest of your code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiNto7UwPiSK",
        "outputId": "b081603f-fa10-4197-ecaf-1b1fef1039a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Found 9246 images belonging to 2 classes.\n",
            "Found 829 images belonging to 2 classes.\n",
            "Found 506 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('inception_best_model.keras', save_best_only=True)\n",
        "\n",
        "# Define the model\n",
        "# Load pre-trained InceptionV3 model\n",
        "base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(299, 299, 3))\n",
        "base_model.trainable = False  # Freeze base layers\n",
        "\n",
        "# Build the model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation=\"sigmoid\")  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',  # You can choose a different optimizer if needed\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=10,\n",
        "    steps_per_epoch=len(train_data),  # Or a fixed value\n",
        "    validation_steps=len(valid_data),  # Or a fixed value\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OucHxAoibjBU",
        "outputId": "74d8b2ee-7dc5-47d3-ae10-d506d88efddf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728ms/step - accuracy: 0.6817 - loss: 0.6281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 810ms/step - accuracy: 0.6820 - loss: 0.6277 - val_accuracy: 0.8504 - val_loss: 0.3653\n",
            "Epoch 2/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 702ms/step - accuracy: 0.8186 - loss: 0.4000 - val_accuracy: 0.8637 - val_loss: 0.3874\n",
            "Epoch 4/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 699ms/step - accuracy: 0.8621 - loss: 0.3179 - val_accuracy: 0.8890 - val_loss: 0.2655\n",
            "Epoch 6/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 696ms/step - accuracy: 0.8857 - loss: 0.2846 - val_accuracy: 0.8951 - val_loss: 0.2389\n",
            "Epoch 8/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 699ms/step - accuracy: 0.8872 - loss: 0.2652 - val_accuracy: 0.9095 - val_loss: 0.2483\n",
            "Epoch 10/10\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1tEVsJizabDm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}